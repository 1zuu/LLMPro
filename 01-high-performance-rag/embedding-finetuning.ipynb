{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, openai, yaml, os\n",
    "import http.client as httplib\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.schema import MetadataMode\n",
    "from llama_index.llm_predictor import LLMPredictor\n",
    "from llama_index import set_global_service_context\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from llama_index.node_parser import SimpleNodeParser, SentenceWindowNodeParser\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.finetuning import (\n",
    "                                    generate_qa_embedding_pairs,\n",
    "                                    EmbeddingQAFinetuneDataset,\n",
    "                                    SentenceTransformersFinetuneEngine\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/1zuu/Desktop/LLM RESEARCH/LLMPro/cadentials.yaml') as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['AD_OPENAI_API_KEY'] = credentials['AD_OPENAI_API_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = credentials['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/Camel Papers Train/'\n",
    "val_dir = 'data/Camel Papers Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(directory, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files in {directory}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(directory)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_llm = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "llm=AzureOpenAI(\n",
    "                deployment_name=credentials['AD_DEPLOYMENT_ID'],\n",
    "                model=credentials['AD_ENGINE'],\n",
    "                api_key=credentials['AD_OPENAI_API_KEY'],\n",
    "                api_version=credentials['AD_OPENAI_API_VERSION'],\n",
    "                azure_endpoint=credentials['AD_OPENAI_API_BASE']\n",
    "                )\n",
    "chat_llm = LLMPredictor(llm)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "                                                embed_model=embedding_llm,\n",
    "                                                llm_predictor=chat_llm\n",
    "                                                )\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in data/Camel Papers Train/\n",
      "Loaded 91 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 91/91 [00:00<00:00, 354.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 156 nodes\n",
      "Loading files in data/Camel Papers Test/\n",
      "Loaded 9 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 9/9 [00:00<00:00, 245.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 17 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_nodes = load_corpus(train_dir, verbose=True)\n",
    "val_nodes = load_corpus(val_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:59<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_qa_embedding_pairs(train_nodes, llm=llm)\n",
    "train_dataset.save_json(\"generated/train_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:20<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = generate_qa_embedding_pairs(val_nodes, llm=llm)\n",
    "val_dataset.save_json(\"generated/val_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"generated/train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"generated/val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "                                                    train_dataset,\n",
    "                                                    model_id=\"BAAI/bge-small-en-v1.5\",\n",
    "                                                    model_output_path=\"bge-small-finetuned\",\n",
    "                                                    val_dataset=val_dataset,\n",
    "                                                    epochs=2\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 31/31 [02:40<00:00,  5.19s/it]\n",
      "Iteration: 100%|██████████| 31/31 [02:39<00:00,  5.13s/it]\n",
      "Epoch: 100%|██████████| 2/2 [05:24<00:00, 162.05s/it]\n"
     ]
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_embedding_llm = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuned Embedding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_st(\n",
    "                dataset,\n",
    "                model_id,\n",
    "                name,\n",
    "                ):\n",
    "    \n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
    "    model = SentenceTransformer(model_id)\n",
    "    output_path = \"results/\"\n",
    "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
    "    return evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7340686274509803"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"BAAI/bge-small-en-v1.5\", name=\"bge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277777777777778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"bge-small-finetuned\", name=\"finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
